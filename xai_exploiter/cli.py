"""
CLI Module for SHAP XAI Exploiter
Author: Roshan Raundal
Date: September 2025
Purpose: Command-line interface for SHAP explanations
"""

import click
import pandas as pd
import numpy as np
import joblib
import os
import sys
from typing import Optional, Any
import json

# Import our custom modules
try:
    from .shap_explainer import SHAPExplainer
    from .visualizations import SHAPVisualizer
except ImportError:
    # Handle direct execution
    from shap_explainer import SHAPExplainer
    from visualizations import SHAPVisualizer


@click.group()
@click.version_option(version='0.1.0')
def main():
    """
    üîç XAI Exploiter - SHAP Component
    
    Author: Roshan Raundal
    Project: Python Library for BlackBox AI Exploitation
    University: University of Mumbai
    
    A comprehensive SHAP-based explainability tool for machine learning models.
    """
    click.echo("üöÄ XAI Exploiter - SHAP Component")
    click.echo("üìß Developed by: Roshan Raundal")


@main.command()
@click.option('--model-path', '-m', required=True, 
              help='Path to the trained model file (.pkl, .joblib)')
@click.option('--data-path', '-d', required=True, 
              help='Path to the dataset file (.csv, .json)')
@click.option('--instance-idx', '-i', default=0, 
              help='Index of the instance to explain (default: 0)')
@click.option('--output-dir', '-o', default='./explanations', 
              help='Output directory for results (default: ./explanations)')
@click.option('--explainer-type', '-e', 
              type=click.Choice(['auto', 'tree', 'kernel', 'explainer']),
              default='auto', help='Type of SHAP explainer to use')
@click.option('--feature-names', '-f', 
              help='Path to JSON file containing feature names')
@click.option('--max-background', default=100, 
              help='Maximum background samples to use (default: 100)')
def explain_instance(model_path: str, data_path: str, instance_idx: int, 
                    output_dir: str, explainer_type: str, 
                    feature_names: Optional[str], max_background: int):
    """
    Explain a single instance prediction using SHAP
    
    Examples:
    
        shap-xai explain-instance -m model.pkl -d data.csv -i 5
        
        shap-xai explain-instance -m model.pkl -d data.csv -i 0 -e tree -o ./results
    """
    try:
        click.echo(f"üîç Explaining instance {instance_idx}...")
        
        # Create output directory
        os.makedirs(output_dir, exist_ok=True)
        
        # Load model
        click.echo(f"üìÇ Loading model from {model_path}")
        model = joblib.load(model_path)
        
        # Load data
        click.echo(f"üìä Loading data from {data_path}")
        if data_path.endswith('.csv'):
            data = pd.read_csv(data_path)
        elif data_path.endswith('.json'):
            data = pd.read_json(data_path)
        else:
            raise ValueError("Data file must be .csv or .json")
        
        # Load feature names if provided
        feature_names_list = None
        if feature_names:
            with open(feature_names, 'r') as f:
                feature_names_list = json.load(f)
        elif isinstance(data, pd.DataFrame):
            feature_names_list = data.columns.tolist()
        
        # Validate instance index
        if instance_idx >= len(data):
            raise ValueError(f"Instance index {instance_idx} is out of range. Data has {len(data)} rows.")
        
        # Initialize explainer
        click.echo(f"üß† Initializing SHAP explainer (type: {explainer_type})")
        explainer = SHAPExplainer(
            model=model,
            background_data=data.sample(min(max_background, len(data))),
            feature_names=feature_names_list,
            explainer_type=explainer_type
        )
        
        # Get instance to explain
        instance = data.iloc[instance_idx:instance_idx+1]
        
        # Generate explanation
        click.echo("‚ö° Generating SHAP explanation...")
        explanation = explainer.explain_instance(instance)
        
        # Save explanation results
        results_path = os.path.join(output_dir, f'explanation_instance_{instance_idx}.json')
        
        # Convert numpy arrays to lists for JSON serialization
        json_explanation = {
            'shap_values': explanation['shap_values'].tolist() if isinstance(explanation['shap_values'], np.ndarray) else explanation['shap_values'],
            'expected_value': float(explanation['expected_value']),
            'prediction': float(explanation['prediction']),
            'instance_idx': instance_idx,
            'feature_names': explanation['feature_names']
        }
        
        with open(results_path, 'w') as f:
            json.dump(json_explanation, f, indent=2)
        
        # Generate visualizations
        click.echo("üé® Creating visualizations...")
        visualizer = SHAPVisualizer()
        
        # Waterfall plot
        waterfall_path = os.path.join(output_dir, f'waterfall_instance_{instance_idx}.png')
        visualizer.waterfall_plot(explanation, save_path=waterfall_path)
        
        # Force plot HTML
        force_path = os.path.join(output_dir, f'force_plot_instance_{instance_idx}.html')
        visualizer.force_plot_html(explanation, save_path=force_path)
        
        # Summary
        click.echo("‚úÖ Instance explanation completed!")
        click.echo(f"üìä Prediction: {explanation['prediction']:.4f}")
        click.echo(f"üìà Expected Value: {explanation['expected_value']:.4f}")
        click.echo(f"üíæ Results saved to: {output_dir}")
        
    except Exception as e:
        click.echo(f"‚ùå Error: {str(e)}")
        sys.exit(1)


@main.command()
@click.option('--model-path', '-m', required=True, 
              help='Path to the trained model file')
@click.option('--data-path', '-d', required=True, 
              help='Path to the dataset file')
@click.option('--output-dir', '-o', default='./global_analysis', 
              help='Output directory for results')
@click.option('--max-samples', default=1000, 
              help='Maximum samples to analyze (default: 1000)')
@click.option('--explainer-type', '-e', 
              type=click.Choice(['auto', 'tree', 'kernel', 'explainer']),
              default='auto', help='Type of SHAP explainer')
@click.option('--generate-report', is_flag=True, 
              help='Generate comprehensive HTML report')
def analyze_global(model_path: str, data_path: str, output_dir: str, 
                  max_samples: int, explainer_type: str, generate_report: bool):
    """
    Perform global SHAP analysis on dataset
    
    Examples:
    
        shap-xai analyze-global -m model.pkl -d data.csv
        
        shap-xai analyze-global -m model.pkl -d data.csv --generate-report --max-samples 500
    """
    try:
        click.echo("üåç Starting global SHAP analysis...")
        
        # Create output directory
        os.makedirs(output_dir, exist_ok=True)
        
        # Load model and data
        click.echo(f"üìÇ Loading model and data...")
        model = joblib.load(model_path)
        
        if data_path.endswith('.csv'):
            data = pd.read_csv(data_path)
        elif data_path.endswith('.json'):
            data = pd.read_json(data_path)
        else:
            raise ValueError("Data file must be .csv or .json")
        
        # Sample data if needed
        if len(data) > max_samples:
            data = data.sample(n=max_samples, random_state=42)
            click.echo(f"üìä Sampled {max_samples} instances from dataset")
        
        # Initialize explainer
        click.echo(f"üß† Initializing SHAP explainer...")
        explainer = SHAPExplainer(
            model=model,
            background_data=data.sample(min(100, len(data))),
            feature_names=data.columns.tolist() if isinstance(data, pd.DataFrame) else None,
            explainer_type=explainer_type
        )
        
        # Generate global explanations
        click.echo("‚ö° Computing SHAP values for all instances...")
        global_explanation = explainer.explain_global(data)
        
        # Calculate feature importance
        importance_df = explainer.get_feature_importance(data)
        
        # Save feature importance
        importance_path = os.path.join(output_dir, 'feature_importance.csv')
        importance_df.to_csv(importance_path, index=False)
        
        # Generate visualizations
        click.echo("üé® Creating visualizations...")
        visualizer = SHAPVisualizer()
        
        # Summary plot
        summary_path = os.path.join(output_dir, 'summary_plot.png')
        visualizer.summary_plot(
            global_explanation['shap_values'],
            global_explanation['data'],
            global_explanation['feature_names'],
            save_path=summary_path
        )
        
        # Feature importance plot
        importance_plot_path = os.path.join(output_dir, 'feature_importance.png')
        visualizer.feature_importance_plot(importance_df, save_path=importance_plot_path)
        
        # Generate comprehensive report if requested
        if generate_report:
            click.echo("üìù Generating comprehensive report...")
            report_path = visualizer.generate_report(global_explanation, output_dir)
            click.echo(f"üìã Report generated: {report_path}")
        
        click.echo("‚úÖ Global analysis completed!")
        click.echo(f"üíæ Results saved to: {output_dir}")
        
    except Exception as e:
        click.echo(f"‚ùå Error: {str(e)}")
        sys.exit(1)


@main.command()
@click.option('--model-path', '-m', required=True, 
              help='Path to the trained model file')
@click.option('--data-path', '-d', required=True, 
              help='Path to the dataset file')
@click.option('--port', '-p', default=8501, 
              help='Port to run dashboard (default: 8501)')
@click.option('--host', default='localhost', 
              help='Host to run dashboard (default: localhost)')
def dashboard(model_path: str, data_path: str, port: int, host: str):
    """
    Launch interactive SHAP dashboard
    
    Examples:
    
        shap-xai dashboard -m model.pkl -d data.csv
        
        shap-xai dashboard -m model.pkl -d data.csv -p 8080
    """
    try:
        click.echo("üöÄ Launching SHAP dashboard...")
        
        # Validate files exist
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"Model file not found: {model_path}")
        if not os.path.exists(data_path):
            raise FileNotFoundError(f"Data file not found: {data_path}")
        
        # Set environment variables for Streamlit app
        os.environ['SHAP_MODEL_PATH'] = model_path
        os.environ['SHAP_DATA_PATH'] = data_path
        
        # Import and run streamlit
        try:
            import streamlit.web.cli as stcli
            import sys
            
            # Get the dashboard script path
            dashboard_script = os.path.join(os.path.dirname(__file__), '..', 'dashboard', 'streamlit_app.py')
            
            # Run streamlit
            sys.argv = ["streamlit", "run", dashboard_script, "--server.port", str(port), "--server.address", host]
            stcli.main()
            
        except ImportError:
            click.echo("‚ùå Streamlit not installed. Install with: pip install streamlit")
            sys.exit(1)
            
    except Exception as e:
        click.echo(f"‚ùå Error launching dashboard: {str(e)}")
        sys.exit(1)


@main.command()
@click.option('--model-path', '-m', required=True, 
              help='Path to the trained model file')
@click.option('--data-path', '-d', required=True, 
              help='Path to the dataset file')
@click.option('--feature-idx', '-f', required=True, type=int,
              help='Index of feature for dependence plot')
@click.option('--output-path', '-o', default='./dependence_plot.png', 
              help='Output path for plot')
@click.option('--interaction-idx', '-int', type=int, 
              help='Index of interaction feature')
def dependence(model_path: str, data_path: str, feature_idx: int, 
              output_path: str, interaction_idx: Optional[int]):
    """
    Create SHAP dependence plot for a specific feature
    
    Examples:
    
        shap-xai dependence -m model.pkl -d data.csv -f 0
        
        shap-xai dependence -m model.pkl -d data.csv -f 2 -int 5
    """
    try:
        click.echo(f"üìä Creating dependence plot for feature {feature_idx}...")
        
        # Load model and data
        model = joblib.load(model_path)
        if data_path.endswith('.csv'):
            data = pd.read_csv(data_path)
        else:
            data = pd.read_json(data_path)
        
        # Initialize explainer
        explainer = SHAPExplainer(model, background_data=data.sample(min(100, len(data))))
        
        # Generate global explanations
        global_explanation = explainer.explain_global(data.sample(min(500, len(data))))
        
        # Create visualizer and dependence plot
        visualizer = SHAPVisualizer()
        visualizer.dependence_plot(
            global_explanation['shap_values'],
            global_explanation['data'],
            feature_idx,
            interaction_feature=interaction_idx,
            feature_names=global_explanation['feature_names'],
            save_path=output_path
        )
        
        click.echo(f"‚úÖ Dependence plot saved to: {output_path}")
        
    except Exception as e:
        click.echo(f"‚ùå Error: {str(e)}")
        sys.exit(1)


@main.command()
def info():
    """Display information about the SHAP XAI Exploiter"""
    info_text = """
    üîç XAI Exploiter - SHAP Component
    
    üìß Author: Roshan Raundal
    üè´ University: University of Mumbai
    üìù Project: Python Library for BlackBox AI Exploitation
    
    üéØ Features:
    ‚Ä¢ Automatic SHAP explainer selection (Tree, Kernel, General)
    ‚Ä¢ Support for tabular data explanations
    ‚Ä¢ Individual instance explanations
    ‚Ä¢ Global model analysis
    ‚Ä¢ Interactive dashboard with Streamlit
    ‚Ä¢ Comprehensive visualizations
    ‚Ä¢ CLI interface for automation
    ‚Ä¢ Export capabilities (JSON, HTML, PNG)
    
    üöÄ Quick Start:
    1. Install: pip install -e .
    2. Explain instance: shap-xai explain-instance -m model.pkl -d data.csv
    3. Global analysis: shap-xai analyze-global -m model.pkl -d data.csv
    4. Dashboard: shap-xai dashboard -m model.pkl -d data.csv
    
    üìö Documentation: README.md
    """
    click.echo(info_text)


if __name__ == '__main__':
    main()